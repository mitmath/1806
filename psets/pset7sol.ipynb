{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18.06 pset 7\n",
    "\n",
    "Due Wednesday, October 24 at 10:55am via Stellar.   Related material *will* be on exam 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (10 points)\n",
    "\n",
    "Find an orthonormal basis for $N(A)$, where $A$ is the matrix\n",
    "$A = \\begin{pmatrix} 1 & 1 & -1 & 1\\end{pmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "First let us find a basis for $N(A)$. The matrix $A$ is already in reduced row echelon form, where the first column is the pivot column and the second, third and fourth columns are free columns. There will then be three special solutions to $Ax = 0$ of the form:\n",
    "\\begin{align}\n",
    "a = \\begin{pmatrix} x_1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\;\\;\n",
    "b = \\begin{pmatrix} x_2 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\;\\; \n",
    "c = \\begin{pmatrix} x_3 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix}.\n",
    "\\end{align}\n",
    "We find that $x_1 = -1, x_2 = 1$ and $x_3 = -1$, so that a basis for $N(A)$ is given by:\n",
    "\\begin{align}\n",
    "a = \\begin{pmatrix} -1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\;\\;\n",
    "b = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\;\\; \n",
    "c = \\begin{pmatrix} -1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix}.\n",
    "\\end{align}\n",
    "We can then use Gram Schmidt to find an orthogonal basis for $N(A)$. We firstly let $A = a$. Our next step is to construct a $B$ orthogonal to $A$:\n",
    "\\begin{align}\n",
    "B &= b - \\left(\\frac{A^Tb}{A^TA}\\right) A\\\\\n",
    "  &= \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix} + \\frac{1}{2} \\begin{pmatrix} -1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\\\\\n",
    "  &= \\begin{pmatrix} 1/2 \\\\ 1/2 \\\\ 1 \\\\ 0 \\end{pmatrix}\n",
    "\\end{align}\n",
    "And then to construct $C$ which is orthogonal to $A$ and $B$ :\n",
    "\\begin{align}\n",
    "C &= c - \\frac{A^Tc}{A^TA} A - \\frac{B^Tc}{B^TB} B\\\\\n",
    "  &= \\begin{pmatrix} -1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix} + \\frac{1}{2} \\begin{pmatrix} -1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix} + \\frac{1}{3} \\begin{pmatrix} 1/2 \\\\ 1/2 \\\\ 1 \\\\ 0 \\end{pmatrix}\\\\\n",
    "  &= \\begin{pmatrix} -1/3 \\\\ -1/3 \\\\ 1/3 \\\\ 1 \\end{pmatrix}\n",
    "\\end{align}\n",
    "Finally we divide by the magnitudes of $A, B$ and $C$ to get an orthonormal basis for $N(A)$:\n",
    "\\begin{align}\n",
    "q_1 = \\frac{A}{\\Vert A \\Vert} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} -1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\;\\;\n",
    "q_2 = \\frac{B}{\\Vert B \\Vert} = \\sqrt{\\frac{2}{3}}\\begin{pmatrix} 1/2 \\\\ 1/2 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\;\\;\n",
    "q_3 = \\frac{C}{\\Vert C \\Vert} = \\frac{\\sqrt{3}}{2}\\begin{pmatrix} -1/3 \\\\ -1/3 \\\\ 1/3 \\\\ 1 \\end{pmatrix}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (8+2 points)\n",
    "\n",
    "The ordinary Gram–Schmidt algorithm only works for linearly independent vectors, i.e. you can only apply it to the columns of $A$ if $A$ has full column rank.\n",
    "\n",
    "**(a)** If $A$ does *not* have full column rank, what goes wrong when you apply Gram–Schmidt to its columns?  Construct an example matrix $A$ that illustrates this problem.\n",
    "\n",
    "**(b)** If you have a matrix $A$ that does *not* have full column rank, you could get an orthonormal basis for $C(A)$ by applying Gram–Schmidt to the ............... columns of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution \n",
    "\n",
    "**(a)** If we try to apply Gram Schmidt to a set of linearly dependent, then the algorithm will generate a zero vector. Consider the following $3\\times 3$ matrix:\n",
    "\\begin{align}\n",
    "M = \\begin{pmatrix} 1 & 2 & 1 \\\\ 1 & 2 & 2 \\\\ 1 & 2 & 3 \\end{pmatrix}\n",
    "\\end{align}\n",
    "This matrix does not have full rank since the second column is a multiple of the first column. Let us try to apply Gram Schmidt to this matrix: We identify the three columns of the matrix:\n",
    "\\begin{align}\n",
    "a = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\;\\;\n",
    "b = \\begin{pmatrix} 2 \\\\ 2 \\\\ 2 \\end{pmatrix}, \\;\\;\n",
    "c = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}.\n",
    "\\end{align}\n",
    "We then let $A=a$. We then construct a $B$ orthogonal to $A$:\n",
    "\\begin{align}\n",
    "b &= b - \\frac{A^T b}{A^TA}\\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} \\\\\n",
    "  &= \\begin{pmatrix} 2 \\\\ 2 \\\\ 2 \\end{pmatrix} - 2\\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}\\\\\n",
    "  &= \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n",
    "\\end{align}\n",
    "This is a problem firstly because the algorithm will then fail at the next step because at some point we will need to divide by $B^TB = 0$. Furthermore, we know that no linearly independent set can contain the zero vector, so $A$ and $B$ in this example are *not* linearly independent.\n",
    "\n",
    "**(b)** If you have a matrix $A$ that does *not* have full column rank, you could get an orthonormal basis for $C(A)$ by applying Gram–Schmidt to the **pivot** columns of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (10 points)\n",
    "\n",
    "If $A$ is an $m \\times n$ real matrix with full column rank, then we learned that Gram–Schmidt gives us the factorization $A=\\hat{Q} \\hat{R}$, where $\\hat{Q}$ is an $m \\times n$ matrix with orthonormal columns ($\\hat{Q}^T \\hat{Q} = I$) and $\\hat{R}$ is an $n \\times n$ invertible upper-triangular matrix.  (This is sometimes called the \"thin\" QR factorization.)\n",
    "\n",
    "Suppose that, instead, we want a factorization $A = QR$ where $Q$ is a *square* $m \\times m$ matrix that is orthogonal (unitary): $Q^T = Q^{-1}$.\n",
    "\n",
    "**(a)** We can find such a $Q$ in the form $Q = \\begin{pmatrix} \\hat{Q} & V \\end{pmatrix}$ by adding $m-n$ columns $V$ to $\\hat{Q}$, if the columns of $V$ are an orthonormal basis for the ............. space of $A$.\n",
    "\n",
    "**(b)** Given $Q = \\begin{pmatrix} \\hat{Q} & V \\end{pmatrix}$ from (a), then $A = QR$ where $R$ is the $? \\, \\times \\, ?$ matrix formed by taking $\\hat{R}$ and .......... (write $R$ in terms of $\\hat{R}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "**(a)** We can find such a $Q$ in the form $Q = \\begin{pmatrix} \\hat{Q} & V \\end{pmatrix}$ by adding $m-n$ columns $V$ to $\\hat{Q}$, if the columns of $V$ are an orthonormal basis for the left null space, $N(A^T)$. This is because the left null space is the orthogonal complement of the column space $C(A)$.\n",
    "\n",
    "**(b)** Given $Q = \\begin{pmatrix} \\hat{Q} & V \\end{pmatrix}$ from (a), then $A = QR$ where $R$ is the $m\\times n$ matrix formed by taking $\\hat{R}$ and a zero matrix of size $(m-n) \\times n$ and concatenating as:\n",
    "\\begin{align}\n",
    "R = \\begin{pmatrix} \\hat{R} \\\\ 0 \\end{pmatrix}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (15 points)\n",
    "\n",
    "Suppose that we apply the Gram–Schmidt process to the columns of an $m \\times n$ matrix $A$ (of rank $n$), but in *reverse order*: we start with the *rightmost* column of $A$ and work from right to left.  We will still obtain a matrix $Q_r$ with orthonormal columns and $C(Q_r)=C(A)$.\n",
    "\n",
    "**(a)** If we compute the matrix $M = Q_r^T A$ for this $Q_r$ from \"reversed\" Gram–Schmidt, which entries of $M$ *must* be zero?  (Is $M$ some type of \"triangular\" matrix, and what shape if so?)\n",
    "\n",
    "**(b)** The function `flipdim(A, 2)` in Julia reverses the order of the columns of a matrix `A`.   The function `Q, R = qr(A)` computes the ordinary QR factorization (equivalent to Gram–Schmidt up to sign flips).\n",
    "Combine `flipdim` and `qr` to obtain the \"reverse-order\" $Q_r$ matrix from above for the following $6\\times 4$ matrix $A$, and check that $Q_r^T A$ (computed via Julia) has the pattern of zero entries you predicted in (a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "**(a)** Suppose we perform Gram–Schmidt in reverse order. Suppose $A$ has columns $a_1$ through $a_n$. We set the $n$th column of $Q_r$ to be the (normalized) $n$th column of $A$. We then apply Gram–Schmidt to calculate the columns of $Q_r$ moving from right to left, to calculate $Q_r = \\begin{pmatrix} q_1 & q_2 & \\cdots & q_n\\end{pmatrix}$. Then $q_n$ and $a_n$ are along the same line; $q_n$ and $q_{n-1}$ lie in the same plane spanned by $a_n$ and $a_{n-1}$; and so on. This means that each $q_i$ is a linear combination of only the $a_j$ for $j\\geq i$. This means that the matrix $M = Q_r^T A$ will be a **lower-triangular**, $n\\times n$ matrix. \n",
    "\n",
    "**Note** The problem wording was somewhat ambiguous as to whether the columns of $Q_r$ are ordered from right to left (above) or from left to right as they are computed.  If you used the left-to-right ordering in $Q_r$, this would reverse the order of the rows of $Q_r^T A$, which would give you a lower-triangular matrix flipped upside-down as shown in the example below.\n",
    "\n",
    "**(b)** We can verify the shape of $M$ for an example $6\\times 4$ matrix $A$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×4 Array{Int64,2}:\n",
       " 7  2  6   9\n",
       " 2  4  3   2\n",
       " 8  6  4  10\n",
       " 4  9  2   5\n",
       " 7  1  5   9\n",
       " 7  8  4   6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [ 7  2  6   9\n",
    "      2  4  3   2\n",
    "      8  6  4  10\n",
    "      4  9  2   5\n",
    "      7  1  5   9\n",
    "      7  8  4   6 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×4 Array{Float64,2}:\n",
       " -0.215439    0.328782   -0.37914    -0.497701\n",
       " -0.343633   -0.291931   -0.672947   -0.1106  \n",
       "  0.0212359  -0.0275592   0.520643   -0.553001\n",
       " -0.497843   -0.632918    0.260321   -0.276501\n",
       "  0.034441    0.43083    -0.0259241  -0.497701\n",
       "  0.765518   -0.468743   -0.25276    -0.331801"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can compute Q_r by calculating the QR factorisation of $A$ with its columns reversed, \n",
    "# and then flipping the order of the columns of the Q we obtain.\n",
    "Q, R = qr(flipdim(A, 2))\n",
    "Qᵣ = flipdim(Q, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Array{Float64,2}:\n",
       "   1.58289    0.0       0.0        0.0   \n",
       "  -1.29993   -9.69089  -0.0       -0.0   \n",
       "  -0.74424   -0.03132  -2.83113    0.0   \n",
       " -15.0416   -10.3964   -9.89872  -18.0831"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can then check that QᵣᵀA has the predicted pattern of zeros:\n",
    "\n",
    "round.(Qᵣ'A, 5) # we round to 5 decimal places to make it easier to read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then see that $M=Q_r^T A$ is a lower triangular, $4\\times 4$ matrix as predicted.   If we hadn't reversed the columns of $Q_r$ as well, we would have gotten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Array{Float64,2}:\n",
       " -15.0416   -10.3964   -9.89872  -18.0831\n",
       "  -0.74424   -0.03132  -2.83113    0.0   \n",
       "  -1.29993   -9.69089  -0.0       -0.0   \n",
       "   1.58289    0.0       0.0        0.0   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round.(Q'A, 5) # lower-triangular flipped upside-down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 (15 points)\n",
    "\n",
    "**(a)** Apply Gram-Schmidt to the polynomials ${1, x, x^2}$ to find an orthonormal basis ${q_1,q_2,q_3}$ of polynomials under the inner (\"dot\") product (*different* from the one used in class):\n",
    "$$\n",
    "f \\cdot g = \\int_0^\\infty f(x) g(x) e^{-x} dx\n",
    "$$\n",
    "(Unlike the Legendre polynomials in class, normalize your polynomials $q_k$ to have $\\Vert q_k \\Vert = \\sqrt {q_k \\cdot q_k} = 1$ under this inner product, i.e. to be really ortho*normal*.)\n",
    "\n",
    "* The [following integral](https://en.wikipedia.org/wiki/Gamma_function) will be useful: $\\int_0^\\infty x^n e^{-x} dx = n!$ ($n$ [factorial](https://en.wikipedia.org/wiki/Factorial)) for any integer $n \\ge 0$.\n",
    "\n",
    "**(b)** Consider the function $f(x) = \\begin{cases} x & x < 1 \\\\ 0 & x \\ge 1 \\end{cases}$.   Find the slope $\\alpha$ of the straight line $\\alpha x$ that is the \"best fit\" to $f(x)$ in the sense of minimizing\n",
    "$$\n",
    "\\Vert f - \\alpha x \\Vert^2 = \\int_0^\\infty \\left[ f(x) - \\alpha x \\right]^2 e^{-x} dx\n",
    "$$\n",
    "In particular, find $\\alpha$ by performing the orthogonal projection (with this dot product) of $f(x)$ onto .........?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution \n",
    "\n",
    "**(a)** We have three functions $a(x) = 1, b(x) = x$ and $c(x) = x^2$. Let's firstly use Gram-Schmidt construct an orthogonal set of functions $A(x), B(x), C(x)$:\n",
    "\\begin{align}\n",
    "A(x) &= 1\\\\\n",
    "B(x) &= b(x) - \\frac{A\\cdot b}{A\\cdot A}A(x)\n",
    "\\end{align}\n",
    "Now $A\\cdot A = \\int_0^{\\infty} e^{-x} dx = 1$ and $A\\cdot B = \\int_0^{\\infty} xe^{-x} dx = 1$, so that \n",
    "\\begin{align}\n",
    "B(x) &= x - 1\n",
    "\\end{align}\n",
    "Then \n",
    "\\begin{align}\n",
    "C(x) = c(x) - \\frac{A\\cdot c}{A \\cdot A}A(x) - \\frac{B\\cdot c}{B \\cdot B}B(x),\n",
    "\\end{align}\n",
    "and $A\\cdot c = \\int_0^{\\infty} x^2 e^{-x} dx =2$, $B\\cdot c = \\int_0^{\\infty} x^2(x-1) e^{-x} dx = 4$, and $ B\\cdot B = \\int_0^{\\infty} (x-1)^2 e^{-x} dx = 1$, so that\n",
    "\\begin{align}\n",
    "C(x) &= x^2 - \\frac{2}{1}\\times 1 - \\frac{4}{1} (x-1)\\\\\n",
    "&= x^2 - 4x + 2.\n",
    "\\end{align}\n",
    "Finally we normalize $A, B, C$. We already found that $A\\cdot A = B \\cdot B = 1$. We can calculate $C\\cdot C = \\int_0^{\\infty} (x^2 - 4x + 2)^2 e^{-x} dx = 4$, so that\n",
    "\\begin{align}\n",
    "q_1(x) = 1, \\;\\; q_2(x) = x-1, \\;\\; q_3(x) = \\frac{x^2 - 4x +2}{4}.\n",
    "\\end{align}\n",
    "\n",
    "You might be interested that this is actually a well-known basis of orthogonal polynomials called [Laguerre polynomials](https://en.wikipedia.org/wiki/Laguerre_polynomials).\n",
    "\n",
    "**(b)** We find $\\alpha$ by calculating the orthogonal projection of $f(x)$ onto the span of the function $x$, so that \n",
    "\\begin{align}\n",
    "\\alpha = \\frac{x\\cdot f(x)}{x\\cdot x}\n",
    "\\end{align}\n",
    "Now $x\\cdot x = \\int_0^{\\infty} x^2 e^{-x} dx = 2$, and \n",
    "\\begin{align}\n",
    "x\\cdot f(x) &= \\int_0^{\\infty} xf(x) e^{-x} dx  \\\\\n",
    "&= \\int_0^1 x^2 e^{-x} dx\\\\\n",
    "&= 2 - 5e^{-1}\n",
    "\\end{align}\n",
    "So that \n",
    "\\begin{align}\n",
    "\\alpha = 1 - 5/2e^{-1}.\n",
    "\\end{align}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
