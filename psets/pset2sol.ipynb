{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19c52d5d",
   "metadata": {},
   "source": [
    "# 18.06 Pset 2 Solutions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fccdd16",
   "metadata": {},
   "source": [
    "## Problem 1 (7+3+5 points)\n",
    "\n",
    "\n",
    "Consider the following $5 \\times 5$ matrix, which is *almost* upper triangular:\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "2 & -2 & 0 & 1 & 1\\\\\n",
    "2 & -1 & 1 & -2 & 1\\\\\n",
    " & 3 & 4 & -3 & 1\\\\\n",
    " &  & -2 & -5 & -3\\\\\n",
    " &  &  & 7 & 3\\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Corresponding in Julia to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eba1bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [2 -2 0 1 1; 2 -1 1 -2 1; 0 3 4 -3 1; 0 0 -2 -5 -3; 0 0 0 7 3];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a5189f",
   "metadata": {},
   "source": [
    "\n",
    "**(a)**\n",
    "\n",
    "Compute (by hand) its LU factorization $A = LU$ via Gaussian elimination (i.e. give both $L$ and $U$).\n",
    "\n",
    "Notice any special pattern to the nonzero entries in L and/or U?\n",
    "\n",
    "**(b)**\n",
    "\n",
    "Why doesn't your hand calculation match the output of Julia's `lu(A)` function?   Try it, it's not even close!  (Do `using LinearAlgebra` in order to access the `lu` function.)\n",
    "\n",
    "**(c)**\n",
    "\n",
    "Suppose you carried out arithmetic at the *same rate*, but $A$ was **10 times** larger: a $50\\times 50$ nearly upper triangular matrix (upper triangular + nonzeros just below the diagonal).\n",
    "\n",
    "About how much longer should part (a) take?  10 times, 100 times, 1000 times?\n",
    "\n",
    "Is this different from how it would scale for a general matrix with no special pattern of zero entries?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad132725",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "__a)__  We use Gaussian elimination to perform the following row operations on $A$:  \n",
    "$R_2-R_1, R_3 - 3R_2, R_4 - (-2R_3), R_5 - R_4$.\n",
    "We get $L$ and $U$ as follows:\n",
    "$$\n",
    "L = \\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "0 & 3 & 1 & 0 & 0\\\\\n",
    "0 & 0 &-2 & 1 & 0\\\\\n",
    "0 & 0 & 0 & 1 & 1\\\\\n",
    "\\end{pmatrix}, \\quad\n",
    "U = \\begin{pmatrix}\n",
    "2 & -2 & 0 & 1 & 1\\\\\n",
    "0 & 1 & 1 & -3 & 0\\\\\n",
    "0 & 0 & 1 &  6 & 1\\\\\n",
    "0 & 0 & 0 & 7 & -1\\\\\n",
    "0 & 0 & 0 & 0 & 4\\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "The only nonzero entries in $L$ are the ones along the diagonal and the ones just below the diagonal: this special pattern is called a [bidiagonal matrix](https://en.wikipedia.org/wiki/Bidiagonal_matrix).   The reason it arises here is because our $A$ matrix has only one nonzero entry below the diagonal, so it ends up requiring only a *single* elimination step per column.\n",
    "\n",
    "$U$, on the other hand, has no special nonzero pattern; it is just a generic upper-triangular matrix, such as we always get from Gaussian elimination.\n",
    "\n",
    "__b)__  The output of `lu(A)` does not match our hand calculation because `lu` implemented in Julia chooses to do some row swaps, as we can tell if we look at the permutation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf661572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LU{Float64, Matrix{Float64}, Vector{Int64}}\n",
       "L factor:\n",
       "5×5 Matrix{Float64}:\n",
       " 1.0  0.0        0.0        0.0       0.0\n",
       " 0.0  1.0        0.0        0.0       0.0\n",
       " 0.0  0.0        1.0        0.0       0.0\n",
       " 0.0  0.0       -0.0        1.0       0.0\n",
       " 1.0  0.333333   0.166667  -0.166667  1.0\n",
       "U factor:\n",
       "5×5 Matrix{Float64}:\n",
       " 2.0  -2.0   0.0   1.0   1.0\n",
       " 0.0   3.0   4.0  -3.0   1.0\n",
       " 0.0   0.0  -2.0  -5.0  -3.0\n",
       " 0.0   0.0   0.0   7.0   3.0\n",
       " 0.0   0.0   0.0   0.0   0.666667"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "lu(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fc39cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Matrix{Float64}:\n",
       " 1.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  1.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0  0.0\n",
       " 0.0  0.0  0.0  0.0  1.0\n",
       " 0.0  1.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lu(A).P # the permutation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c329d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Int64}:\n",
       " 1\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lu(A).p # the permutation vector (the permuted order of the rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1367d73d",
   "metadata": {},
   "source": [
    "Of course, Julia is free to re-order the rows if it wants to, which results in different $L$ and $U$ matrices, but why?  It's not necessary in order to avoid zeros, as you saw by hand.\n",
    "\n",
    "As we alluded to in Lecture 5, in practice computers **almost always do row swaps** during Gaussian elimination.  It turns out that they are not just worried about pivots being zero, but in fact they want to avoid pivots that are merely *small*, in order to avoid exacerbating roundoff errors.    The algorithm used by Julia (and, in fact, in virtually all computer numerical linear-algebra systems), is called \"partial pivoting\" — it swaps rows to make the pivot *as big as possible*.\n",
    "\n",
    "We can get the same result as our hand calculation by using `lu(A, NoPivot())`, which forces Julia to avoid row swaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4498c5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LU{Float64, Matrix{Float64}, Vector{Int64}}\n",
       "L factor:\n",
       "5×5 Matrix{Float64}:\n",
       " 1.0  0.0   0.0  0.0  0.0\n",
       " 1.0  1.0   0.0  0.0  0.0\n",
       " 0.0  3.0   1.0  0.0  0.0\n",
       " 0.0  0.0  -2.0  1.0  0.0\n",
       " 0.0  0.0   0.0  1.0  1.0\n",
       "U factor:\n",
       "5×5 Matrix{Float64}:\n",
       " 2.0  -2.0  0.0   1.0   1.0\n",
       " 0.0   1.0  1.0  -3.0   0.0\n",
       " 0.0   0.0  1.0   6.0   1.0\n",
       " 0.0   0.0  0.0   7.0  -1.0\n",
       " 0.0   0.0  0.0   0.0   4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra;\n",
    "lu(A, NoPivot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbc751a",
   "metadata": {},
   "source": [
    "__c)__  Each row operation is requires $\\Theta(n)$ work (i.e. proportional to the number $n$ of columns).   However, for this matrix structure (which is called [upper Hessenberg](https://en.wikipedia.org/wiki/Hessenberg_matrix)), we only need to eliminate *one nonzero per column*, which means that we only need to do $n$ row operations (or actually $n-1$ since the last column has nothing to eliminate).    Hence, the total number of arithmetic operations grows as $\\boxed{\\Theta(n^2)}$, i.e. **roughly proportional to $n^2$**.\n",
    "\n",
    "Thus, if $A$ were $10$ times larger, we would expect to do about $10^2 = 100$ times as much arithmetic.\n",
    "\n",
    "This is very different from how it would scale for a general matrix with no special pattern of zero entries.  For a general matrix, the number of operations for elimination $\\Theta(n^3)$, where $n$ is the size of the matrix, because you have to eliminate $n(n-1)/2$ nonzero entries below the diagonal in general.  In this case, a $10\\times$ larger matrix would require about $1000\\times$ as much arithmetic work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5034ad02",
   "metadata": {},
   "source": [
    "## Problem 2 (8+2 points)\n",
    "\n",
    "Consider the three $4 \\times 4$ matrices\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "1 & -3 & 0 & 3\\\\\n",
    "  & 1 & 1 & 2\\\\\n",
    "  &   & 1 & -1\\\\\n",
    "  &   &   & 1\\\\\n",
    "\\end{pmatrix}, \\;\n",
    "B = \\begin{pmatrix}\n",
    "-3 & -1 & 1 & -2\\\\\n",
    "-3 & 0 & 0 & -3\\\\\n",
    "1 & 3 & 3 & -3\\\\\n",
    "2 & 3 & 2 & 0\\\\\n",
    "\\end{pmatrix}, \\; C = A (AB)^{-1}\n",
    "$$\n",
    "\n",
    "\n",
    "**(a)** Compute the third column of $C^{-1}$ without computing the whole inverse of any matrix.  Think before plugging-and-chugging!\n",
    "\n",
    "**(b)** Check your answer by explicitly computing $C^{-1}$ in Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill these in:\n",
    "A = ??????\n",
    "B = ??????\n",
    "\n",
    "C = A / (A*B)  # computes A(AB)⁻¹\n",
    "C^-1 # computes C⁻¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf1660",
   "metadata": {},
   "source": [
    "### Solution\n",
    "__(a)__ We can compute the third column of $C^{-1}$ without computing the whole inverse of any matrix. Let $x$ be the third column of $C^{-1}$. Then $x = C^{-1} e_3$, where $e_3 = (0,0,1,0)$ is the third column of the $4\\times 4$ identity matrix $I$.    (In fact, this is true for *any* matrix: if you multiply it by a column of $I$, you get the corresponding column of the matrix.)\n",
    "\n",
    "$C = A (AB)^{-1}$ implies that $C^{-1} = AB A^{-1}, and we want to compute\n",
    "$$\n",
    "x = C^{-1} e_3 = A\\underbrace{B \\underbrace{A^{-1} e_3}_y}_z\n",
    "$$\n",
    "We can then do this in three steps:\n",
    "\n",
    "1. Compute $y = A^{-1} e_3$, i.e. solve $Ay = e_3$ for $y$.  As $A$ is upper triangular, we can solve for $y$ by **backsubstitution** to obtain $y = \\begin{pmatrix} -3 \\\\ -1 \\\\ 1 \\\\ 0 \\end{pmatrix}$.\n",
    "\n",
    "2. Compute $z = By$.  This is just a multiplication.  We obtain $z = \\begin{pmatrix} 11 \\\\ 9 \\\\ -3 \\\\ -7 \\end{pmatrix}$\n",
    "\n",
    "3. Compue $x = Az$.  This is just a multiplication.  We obtain $x = \\begin{pmatrix} -37 \\\\ -8 \\\\ 4 \\\\ -7 \\end{pmatrix}$.\n",
    "\n",
    "(Note that it would be a *lot* more work to compute any matrix inverses here.  It would also be a *lot* more work to multiply $AB$ and *then* multiply by $y$ as $(AB)y$, rather than computing $A(By)$ as above.  Parentheses can make a big practical difference in the amount of arithmetic, even though they theoretically do not change the result!)\n",
    "\n",
    "__(b)__ We can compute $C^{-1}$ in Julia as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58988b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Matrix{Float64}:\n",
       " 12.0  44.0  -37.0  -154.0\n",
       "  2.0  15.0   -8.0   -50.0\n",
       " -1.0  -3.0    4.0    10.0\n",
       "  2.0   9.0   -7.0   -31.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [1 -3 0 3; 0 1 1 2; 0 0 1 -1; 0 0 0 1];\n",
    "B = [-3 -1 1 -2; -3 0 0 -3; 1 3 3 -3; 2 3 2 0];\n",
    "C = A / (A*B) # computes A(AB)⁻¹\n",
    "C^-1 # computes C⁻¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b40a7",
   "metadata": {},
   "source": [
    "As in our hand calculation, the third column is indeed $(-37,-8,4,-7)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431096d8",
   "metadata": {},
   "source": [
    "## Problem 3 (12 points)\n",
    "\n",
    "(Based on Strang problems.)\n",
    "\n",
    "Which of the following subsets of $\\mathbb{R^3}$ are actually subspaces?  (Recall that $[x_1,x_2,x_3]$, with commas, denotes a column vector.)   If it is *not* a subspace, give a rule that it violates.\n",
    "\n",
    "1. The plane of vectors $[x_1,x_2,x_3]$ with $x_1 = x_2$\n",
    "2. The plane of vectors $[x_1,x_2,x_3]$ with $x_1 = 1$\n",
    "3. The vectors $[x_1,x_2,x_3]$ satisfying $x_1 x_2 x_3 = 0$\n",
    "4. All linear combinations of $v = [1,4,0]$ and $w = [2,2,2]$\n",
    "5. The vectors $[x_1,x_2,x_3]$ satisfying $x_1 + x_2  + x_3 = 0$\n",
    "6. The vectors $[x_1,x_2,x_3]$ satisfying $x_1 \\le x_2 \\le x_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d83615",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "1. It is a subspace. It is a plane through origin. It is closed under addition and scalar multiplication.\n",
    "2. It is not a subspace as it is not closed under scalar multiplication. For example, $[1,0,0]$ is in the subspace but $[2,0,0]$ is not.\n",
    "3. It is not a subspace as it is not closed under addition. For example, $[1,1,0]$ and $[0,0,1]$ are in the subspace but $[1,1,1]$ is not.\n",
    "4. It is a subspace with basis $v$ and $w$. All vectors in the subspace can be written as $a_1v + a_2w$ for some $a_1$ and $a_2$. It is closed under addition and scalar multiplication.\n",
    "5. It is a subspace. It is a plane through origin. It is closed under addition and scalar multiplication.\n",
    "6. It is *not* a subspace: it is not closed under multiplication by $-1$.  For example, $[1,2,3]$ is in the space but not $[-1,-2,-3]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd2e20d",
   "metadata": {},
   "source": [
    "## Problem 4 (10 points)\n",
    "\n",
    "Nowadays, numerical linear algebra programs deal with small pivots by swapping rows, leading to the $PA = LU$ factorization.   Prof. Edelman mentioned that, in the elder days, people would occasionally swap *columns* instead, leading to a factorization $AP = LU$ for some (different) permutation $P$ (and different $L$ and $U$ matrices). \n",
    "\n",
    "Given a factorization $AP = LU$ for a nonsingular matrix $A$, outline how you would use it to solve $Ax=b$ for $x$ (analogous to how we outlined the use of $PA=LU$ in class).\n",
    "\n",
    "(You can exploit the fact, explained in section 2.7 of the textbook, that you can invert permutations \"for free\": $P^{-1} = P^T$ for any permutation matrix $P$, where the transpose $P^T$ of a matrix is simply formed by swapping the rows of $P$ with the columns of $P$.  We will spend more time on this later in 18.06.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a042a45",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "We are given $AP = LU$, which can be rewritten as $A = LUP^{-1}$ ($= LUP^T$) or equivalently $A^{-1} = P U^{-1} L^{-1}$. We can therefore rewrite $Ax = b$ as $LUP^{-1}x = b$, or equivalently\n",
    "\n",
    "$$\n",
    "x = A^{-1} b = P \\underbrace{U^{-1} \\underbrace{L^{-1} b}_c}_y\n",
    "$$\n",
    "\n",
    "This can be solved in three steps:\n",
    "\n",
    "1. Compute $c = L^{-1}b$, i.e. solve $Lc = b$ for $c$.  This can be done by forward-substitution because $L$ is lower-triangular.\n",
    "2. Compute $y = U^{-1}c$, i.e. solve $Uy = c$ for $y$.  This can be done by back-substitution because $U$ is upper-triangular.\n",
    "3. Compute $x = Py$.  This is just a permutation of $y$.\n",
    "\n",
    "Note that we didn't actually need to invert the permutation $P$, although it is easy to do if we wanted to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb5aa6",
   "metadata": {},
   "source": [
    "## Problem 5 (9 points)\n",
    "\n",
    "Suppose we have a $3 \\times 3$ matrix $A$.  We will transform this into a *new* matrix $B$ by doing operations on the rows or columns of $A$ as follows.   For each part, explain how to compute $B$ as $B=EA$ or $B=AE$ (say which!) and give the matrix $E$.\n",
    "\n",
    "1. Reverse the order of the rows of $A$.\n",
    "2. Add the second row to the third row, *then* replace the second row with the sum of the first and (new) third rows.\n",
    "3. Subtract the third column from the first and second columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdb89f8",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "1. As we are permuting the order of the rows, we should left multiply with $E$. The permutation matrix which reverses the rows is given by $E = \\begin{pmatrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\end{pmatrix}$ and $B = EA$.\n",
    "2. We still want to perform the operation on rows, so we will left-multiply with $E$. We have to find an $E$ such that $E\\begin{pmatrix} R_1 \\\\ R_2 \\\\ R_3 \\end{pmatrix} = \\begin{pmatrix} R_1 \\\\ R_1+(R_3 + R_2) \\\\ R_3 + R_2 \\end{pmatrix}$. We can find $E = \\begin{pmatrix} 1 & 0 & 0 \\\\ 1 & 1 & 1 \\\\ 0 & 1 & 1 \\end{pmatrix}$ and $B = EA$.\n",
    "3. As we are performing the operation on columns, we want to multiply with $E$ on the right. We have to find an $E$ such that $\\begin{pmatrix} C_1 & C_2 & C_3 \\end{pmatrix}E = \\begin{pmatrix} C_1 - C_3 & C_2 - C_3 & C_3 \\end{pmatrix}$. We can find $E$ as $E = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ -1 & -1 & 1 \\end{pmatrix}$ and $B = AE$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
